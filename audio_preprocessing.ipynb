{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, scipy, matplotlib.pyplot as plt, sklearn, librosa, urllib, IPython.display\n",
    "import pandas as pd\n",
    "#import essentia, essentia.standard as ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 679) (12, 679)\n"
     ]
    }
   ],
   "source": [
    "maxi = -1\n",
    "\n",
    "mini = 1000000\n",
    "\n",
    "for i in range(1, 2):\n",
    "\n",
    "    x, fs = librosa.load('data/audio/q'+str(i)+'.wav')\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "    mfccs = mfccs[1: , ]\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "    \n",
    "    hop_length = 512\n",
    "    chromagram = librosa.feature.chroma_stft(x, sr=fs, hop_length=hop_length)\n",
    "    \n",
    "    #print(mfccs.shape, chromagram.shape)\n",
    "\n",
    "    if(maxi < mfccs.shape[1]):\n",
    "        maxi = mfccs.shape[1]\n",
    "        I = i\n",
    "        \n",
    "    if(mini > mfccs.shape[1]):\n",
    "        mini = mfccs.shape[1]\n",
    "        J = i\n",
    "        \n",
    "    #print(mfccs.shape)\n",
    "    #print(mfccs.mean(axis=1))\n",
    "    #print(mfccs.var(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxi, I, mini, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = -1\n",
    "\n",
    "mini = 1000000\n",
    "\n",
    "for i in range(1, 119):\n",
    "    print(i, end='\\r')\n",
    "    x, fs = librosa.load('data/metadata/songs/s'+str(i)+'.wav')\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "    mfccs = mfccs[1: , ]\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "\n",
    "    if(maxi < mfccs.shape[1]):\n",
    "        maxi = mfccs.shape[1]\n",
    "        I = i\n",
    "        \n",
    "    if(mini > mfccs.shape[1]):\n",
    "        mini = mfccs.shape[1]\n",
    "        J = i\n",
    "        \n",
    "    #print(mfccs.shape)\n",
    "    #print(mfccs.mean(axis=1))\n",
    "    #print(mfccs.var(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maxi, I, mini, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-30850f5e1b29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchromagram\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmfccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_track_gap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mquotient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull_length\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DL\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \"\"\"\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "full_length = 20700\n",
    "inter_track_gap = np.array([[0.0]*31]*14)\n",
    "full_data = []\n",
    "\n",
    "for i in range(1, 2):\n",
    "    \n",
    "    print(i, end = '\\r')\n",
    "\n",
    "    x, fs = librosa.load('data/metadata/songs/s'+str(i)+'.wav')\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "    mfccs = mfccs[1: , ]\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs, axis=1).T\n",
    "    \n",
    "    hop_length = 512\n",
    "    chromagram = librosa.feature.chroma_stft(x, sr=fs, hop_length=hop_length).T\n",
    "    \n",
    "    tonn = librosa.feature.tonnetz(x, sr = fs)\n",
    "    print(mfccs.shape, chromagram.shape, tonn.shape)\n",
    "    \n",
    "    mfccs =  np.hstack([mfccs, chromagram])\n",
    "\n",
    "    mfccs = np.vstack((mfccs, inter_track_gap))\n",
    "    \n",
    "    quotient = full_length//(mfccs.shape[0])\n",
    "    remainder = full_length%(mfccs.shape[0])\n",
    "    \n",
    "    if(quotient != 0):\n",
    "        mfccs = np.tile(mfccs, (quotient,1))\n",
    "        mfccs = np.vstack((mfccs, mfccs[0:remainder]))\n",
    "        \n",
    "    else:\n",
    "        mfccs = mfccs[0:20700]\n",
    "        \n",
    "    full_data.append(mfccs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = np.array(full_data)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arbaazQureshi\\Anaconda3\\envs\\DL\\lib\\site-packages\\scipy\\fftpack\\basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 430)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arbaazQureshi\\Anaconda3\\envs\\DL\\lib\\site-packages\\scipy\\fftpack\\basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1069, 430)\n"
     ]
    }
   ],
   "source": [
    "full_length = 20700\n",
    "inter_track_gap = np.array([[0.0]*19]*14)\n",
    "\n",
    "full_data = []\n",
    "\n",
    "for i in range(1, 3):\n",
    "    \n",
    "    #print(i, end='\\r')\n",
    "    \n",
    "    x, fs = librosa.load('data/testing_data/queries/tq'+str(i)+'.wav')\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "    mfccs = mfccs[1: , ]\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs, axis=1).T\n",
    "    \n",
    "    hop_length = 512\n",
    "    chromagram = librosa.feature.chroma_stft(x, sr=fs, hop_length=hop_length)\n",
    "    chromagram = sklearn.preprocessing.scale(chromagram, axis=1).T\n",
    "    \n",
    "    tonn = librosa.feature.tonnetz(x, sr = fs)\n",
    "    tonn = sklearn.preprocessing.scale(tonn, axis=1).T\n",
    "    \n",
    "    spec_centroid = librosa.feature.spectral_centroid(x, sr=fs)\n",
    "    spec_centroid = sklearn.preprocessing.scale(spec_centroid, axis=1).T\n",
    "    \n",
    "    spec_bw = librosa.feature.spectral_bandwidth(x, sr=fs)\n",
    "    spec_bw = sklearn.preprocessing.scale(spec_bw, axis=1).T\n",
    "    \n",
    "    spec_contr = librosa.feature.spectral_contrast(x, sr=fs)\n",
    "    spec_contr = sklearn.preprocessing.scale(spec_contr, axis=1).T\n",
    "    \n",
    "    tempogram = librosa.feature.tempogram(x, sr=fs)\n",
    "    tempogram = sklearn.preprocessing.scale(tempogram, axis=1).T\n",
    "    \n",
    "    #beat_track = librosa.beat.beat_track(x, sr=fs)\n",
    "    #print(beat_track[1].shape)\n",
    "    #beat_track = sklearn.preprocessing.scale(beat_track, axis=1).T\n",
    "    \n",
    "    #tempo = librosa.beat.tempo(x, sr=fs)\n",
    "    #tempo = sklearn.preprocessing.scale(tempo, axis=1).T\n",
    "    \n",
    "    \n",
    "    #print(mfccs.shape, chromagram.shape, tonn.shape, spec_centroid.shape, spec_bw.shape, spec_contr.shape, tempogram.shape)\n",
    "    mfcss = np.hstack((mfccs, chromagram, tonn, spec_centroid, spec_bw, spec_contr, tempogram))\n",
    "    print(mfcss.shape)\n",
    "    mfccs = np.vstack((mfccs, inter_track_gap))\n",
    "    \n",
    "    quotient = full_length//(mfccs.shape[0])\n",
    "    remainder = full_length%(mfccs.shape[0])\n",
    "    \n",
    "    if(quotient != 0):\n",
    "        mfccs = np.tile(mfccs, (quotient,1))\n",
    "        mfccs = np.vstack((mfccs, mfccs[0:remainder]))\n",
    "        \n",
    "    else:\n",
    "        mfccs = mfccs[0:20700]\n",
    "        \n",
    "    full_data.append(mfccs.tolist())\n",
    "\n",
    "full_data = np.array(full_data)\n",
    "#print(full_data.shape)\n",
    "\n",
    "#np.save('data/all_testing_queries.npy', full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r"
     ]
    }
   ],
   "source": [
    "full_length = 20700\n",
    "inter_track_gap = np.array([[0.0]*19]*14)\n",
    "\n",
    "full_data = []\n",
    "\n",
    "for i in range(2, 3):\n",
    "    \n",
    "    print(i, end='\\r')\n",
    "    \n",
    "    x, fs = librosa.load('data/testing_data/songs/ts'+str(i)+'.wav')\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(x, sr=fs)\n",
    "    mfccs = mfccs[1: , ]\n",
    "    mfccs = sklearn.preprocessing.scale(mfccs, axis=1).T\n",
    "\n",
    "    mfccs = np.vstack((mfccs, inter_track_gap))\n",
    "    \n",
    "    quotient = full_length//(mfccs.shape[0])\n",
    "    remainder = full_length%(mfccs.shape[0])\n",
    "    \n",
    "    if(quotient != 0):\n",
    "        mfccs = np.tile(mfccs, (quotient,1))\n",
    "        mfccs = np.vstack((mfccs, mfccs[0:remainder]))\n",
    "        \n",
    "    else:\n",
    "        mfccs = mfccs[0:20700]\n",
    "        \n",
    "    full_data.append(mfccs.tolist())\n",
    "\n",
    "full_data = np.array(full_data)\n",
    "#print(full_data.shape)\n",
    "\n",
    "np.save('data/all_testing_songs.npy', full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/all_testing_songs.npy', np.vstack([full_data, full_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/all_testing_labels.npy', np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = np.load('data/queries_new.npy')\n",
    "songs = np.load('data/songs_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/metadata/Queries.csv')\n",
    "\n",
    "similar_songs = metadata['Unnamed: 6'].values.tolist()\n",
    "dissimilar_songs = metadata['Unnamed: 7'].values.tolist()\n",
    "\n",
    "for i in range(len(similar_songs)):\n",
    "    similar_songs[i] = int(similar_songs[i][1:]) - 1\n",
    "    dissimilar_songs[i] = int(dissimilar_songs[i][1:]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = np.concatenate([queries, queries, queries], axis = 0)\n",
    "all_songs = np.concatenate([songs, songs[similar_songs], songs[dissimilar_songs]], axis = 0)\n",
    "all_labels = np.array([1]*118 + [0]*2*118)\n",
    "\n",
    "print(all_queries.shape, all_songs.shape, all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.choice(354, 354, replace=False)\n",
    "\n",
    "all_queries = all_queries[perm]\n",
    "all_songs = all_songs[perm]\n",
    "all_labels = all_labels[perm]\n",
    "\n",
    "np.save('data/all_training_queries_new.npy', all_queries)\n",
    "np.save('data/all_training_songs_new.npy', all_songs)\n",
    "np.save('data/all_training_labels_new.npy', all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_queries = np.load('data/all_training_queries.npy')\n",
    "all_training_songs = np.load('data/all_training_songs.npy')\n",
    "all_training_labels = np.load('data/all_training_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/all_testing_queries.npy', all_training_queries[304:])\n",
    "np.save('data/all_testing_labels.npy', all_training_labels[304:])\n",
    "np.save('data/all_testing_songs.npy', all_training_songs[304:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
